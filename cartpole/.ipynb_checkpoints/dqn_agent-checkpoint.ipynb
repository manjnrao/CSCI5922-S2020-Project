{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"saved_data/model_\"\n",
    "INFO_PATH = \"saved_data/info\"\n",
    "BUFFER_PATH = \"saved_data/buffer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self):\n",
    "        self.env_name = 'CartPole-v0'\n",
    "        self.hidden_layer_sizes = [16,16]\n",
    "        self.activation = \"relu\"\n",
    "        self.learning_rate = 0.001\n",
    "        self.buffer_size = 1000\n",
    "        self.batch_size = 32\n",
    "        self.e = 1\n",
    "        self.e_decay = 0.99\n",
    "        self.gamma = 0.99\n",
    "        \n",
    "        self.env = gym.make(self.env_name)\n",
    "        self.state_size = self.env.observation_space.shape[0]\n",
    "        self.num_actions = self.env.action_space.n\n",
    "        \n",
    "        # Load or initialize model\n",
    "        self.model = tf.keras.models.Sequential()\n",
    "        try:\n",
    "            self.model = tf.keras.models.load_model(MODEL_PATH)\n",
    "            print(\"* Model exists, loaded\")\n",
    "        except:\n",
    "            print(\"* Model does not exist, creating\")\n",
    "            self.model.add(tf.keras.layers.Dense(self.hidden_layer_sizes[0], input_shape=(self.state_size,), activation = self.activation))\n",
    "            for num_units in self.hidden_layer_sizes[1:]:\n",
    "                self.model.add(tf.keras.layers.Dense(num_units, activation = self.activation))\n",
    "            self.model.add(tf.keras.layers.Dense(self.num_actions, activation = \"linear\"))\n",
    "            self.model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(lr=self.learning_rate))\n",
    "            self.model.save(MODEL_PATH)\n",
    "            \n",
    "        # Load or initialize training and performance info\n",
    "        self.total_ep_trained = 0\n",
    "        self.scores = deque(maxlen=100) \n",
    "        self.mean_scores = []\n",
    "        try:\n",
    "            f = open(INFO_PATH, 'rb')\n",
    "            info = pickle.load(f)\n",
    "            self.total_ep_trained = info['episodes']\n",
    "            self.scores = info['scores']\n",
    "            self.mean_scores = info['mean_scores']\n",
    "            self.e = info['e']\n",
    "            print(\"* Loaded info:\")\n",
    "            print(\"Model already trained on {} episodes\".format(self.total_ep_trained))\n",
    "            if len(self.scores) != 0:\n",
    "                print(\"Average score on previous 100 episodes is {}\".format(np.mean(self.scores)))\n",
    "        except:\n",
    "            print(\"* No training info, initializing\")\n",
    "            info = dict()\n",
    "            info['episodes'] = 0\n",
    "            info['scores'] = self.scores\n",
    "            info['mean_scores'] = self.mean_scores\n",
    "            info['e'] = self.e\n",
    "            f = open(INFO_PATH, 'wb')\n",
    "            pickle.dump(info, f)\n",
    "            \n",
    "        # Load or initialize memory buffer\n",
    "        self.memory = deque(maxlen=self.buffer_size)\n",
    "        try:\n",
    "            f = open(BUFFER_PATH, 'rb')\n",
    "            self.memory = pickle.load(f)\n",
    "            print(\"* Loaded memory buffer:\")\n",
    "            print(\"Has {} tuples\".format(len(self.memory)))\n",
    "        except:\n",
    "            print(\"* No memory buffer, creating\")\n",
    "            f = open(BUFFER_PATH, 'wb')\n",
    "            pickle.dump(self.memory, f)\n",
    "            \n",
    "        \n",
    "    def save(self):\n",
    "        # Save info\n",
    "        info = dict()\n",
    "        info['episodes'] = self.total_ep_trained\n",
    "        info['scores'] = self.scores\n",
    "        info['mean_scores'] = self.mean_scores\n",
    "        info['e'] = self.e\n",
    "        f = open(INFO_PATH, 'wb')\n",
    "        pickle.dump(info, f)\n",
    "        print(\"* Saved training info\")\n",
    "        # Save model\n",
    "        self.model.save(MODEL_PATH)\n",
    "        print(\"* Saved model\")\n",
    "        # Save memory buffer\n",
    "        f = open(BUFFER_PATH, 'wb')\n",
    "        pickle.dump(self.memory, f)\n",
    "        print(\"* Saved memory buffer\")\n",
    "        \n",
    "    def get_action_best(self, state):\n",
    "        q = self.model.predict(state)\n",
    "        return np.argmax(q)\n",
    "    \n",
    "    def get_action_explore(self, state):\n",
    "        # Random action\n",
    "        if np.random.rand() <= self.e:\n",
    "            return random.randrange(self.num_actions)\n",
    "        # Best action\n",
    "        else:\n",
    "            q = self.model.predict(state)\n",
    "            return np.argmax(q)\n",
    "    \n",
    "    def evaluate(self):\n",
    "        n_episodes = 100\n",
    "        total_reward = 0\n",
    "        for i in range(n_episodes):\n",
    "            episode_reward = 0\n",
    "            done = False\n",
    "            state = self.env.reset()\n",
    "            state = np.reshape(state,(1, self.state_size))\n",
    "            while not done:\n",
    "                action = self.get_action_best(state)\n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "                episode_reward += reward\n",
    "                state = np.reshape(next_state, (1, self.state_size))\n",
    "            total_reward += episode_reward\n",
    "        return total_reward/n_episodes\n",
    "    \n",
    "    def fit_one_batch(self):\n",
    "        '''\n",
    "        Samples a random batch from the memory buffer and fits model\n",
    "        '''\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "        batch = random.sample(self.memory, self.batch_size)\n",
    "        x_train = np.zeros((self.batch_size, self.state_size))\n",
    "        y_train = np.zeros((self.batch_size, self.num_actions))\n",
    "        i = 0\n",
    "        for state, action, reward, next_state in batch:\n",
    "            x_train[i] = state\n",
    "            y_pred = self.model.predict(state)\n",
    "            y_desired = y_pred\n",
    "            y_desired[0][action] = reward + self.gamma*np.max(self.model.predict(next_state))\n",
    "            y_train[i] = y_desired\n",
    "            i += 1\n",
    "        self.model.fit(x_train, y_train, verbose=0)\n",
    "        self.e *= self.e_decay\n",
    "        if self.e < 0.01:\n",
    "            self.e = 0.01\n",
    "            \n",
    "    def train(self, num_episodes):\n",
    "        '''\n",
    "        Trains model over num_episodes\n",
    "        At each time step:\n",
    "        - Generates best or random action\n",
    "        - Steps through env, saves tuple to memory buffer\n",
    "        - Fits model to one batch of the memory buffer\n",
    "        '''\n",
    "        num_episodes -= self.total_ep_trained\n",
    "        print(\"Already trained on {} episodes\".format(self.total_ep_trained))\n",
    "        print(\"Training on remaining {}\".format(num_episodes))\n",
    "        solved = False\n",
    "        print(\"** Training \")\n",
    "        for i in range(num_episodes):  \n",
    "            episode_reward = 0\n",
    "            state = self.env.reset()\n",
    "            state = np.reshape(state,(1, self.state_size))\n",
    "            done = False\n",
    "            while not done:\n",
    "                action = self.get_action_explore(state)\n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "                episode_reward += reward\n",
    "                if done:\n",
    "                    reward = -200\n",
    "                next_state = np.reshape(next_state, (1, self.state_size))\n",
    "                self.memory.append((state, action, reward, next_state))\n",
    "                self.fit_one_batch()\n",
    "                state = next_state\n",
    "                \n",
    "            self.scores.append(episode_reward)  \n",
    "            mean_score = np.mean(self.scores)\n",
    "            self.mean_scores.append(mean_score)\n",
    "            print(\"Episode {} -> Mean score {}\".format(self.total_ep_trained, mean_score)) \n",
    "            if mean_score > 195 and len(self.scores) == 100:\n",
    "                print(\"Solved!\")\n",
    "                print(\"Final epsilon value is {}\".format(self.e))\n",
    "                solved = True\n",
    "                break\n",
    "                \n",
    "            self.total_ep_trained += 1   \n",
    "            i += 1\n",
    "            if i%20 == 0:\n",
    "                self.save()\n",
    "\n",
    "        # Save training info, model and memory\n",
    "        self.save()\n",
    "        if not solved:\n",
    "            print(\"Could not solve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Model exists, loaded\n",
      "* Loaded info:\n",
      "Model already trained on 80 episodes\n",
      "Average score on previous 100 episodes is 44.025\n",
      "* Loaded memory buffer:\n",
      "Has 1000 tuples\n",
      "Already trained on 80 episodes\n",
      "Training on remaining 420\n",
      "** Training \n",
      "Episode 80 -> Mean score 43.65432098765432\n",
      "Episode 81 -> Mean score 43.8780487804878\n",
      "Episode 82 -> Mean score 43.975903614457835\n",
      "Episode 83 -> Mean score 44.142857142857146\n",
      "Episode 84 -> Mean score 44.976470588235294\n",
      "Episode 85 -> Mean score 46.77906976744186\n",
      "Episode 86 -> Mean score 48.51724137931034\n",
      "Episode 87 -> Mean score 48.97727272727273\n",
      "Episode 88 -> Mean score 49.31460674157304\n",
      "Episode 89 -> Mean score 50.98888888888889\n",
      "Episode 90 -> Mean score 52.62637362637363\n",
      "Episode 91 -> Mean score 54.22826086956522\n",
      "Episode 92 -> Mean score 55.795698924731184\n",
      "Episode 93 -> Mean score 57.329787234042556\n",
      "Episode 94 -> Mean score 58.83157894736842\n",
      "Episode 95 -> Mean score 60.302083333333336\n",
      "Episode 96 -> Mean score 61.74226804123711\n",
      "Episode 97 -> Mean score 63.1530612244898\n",
      "Episode 98 -> Mean score 64.44444444444444\n",
      "Episode 99 -> Mean score 65.8\n",
      "* Saved training info\n",
      "INFO:tensorflow:Assets written to: saved_data/model_/assets\n",
      "* Saved model\n",
      "* Saved memory buffer\n",
      "Episode 100 -> Mean score 66.65\n",
      "Episode 101 -> Mean score 68.38\n",
      "Episode 102 -> Mean score 70.12\n",
      "Episode 103 -> Mean score 71.96\n",
      "Episode 104 -> Mean score 73.17\n",
      "Episode 105 -> Mean score 74.54\n",
      "Episode 106 -> Mean score 76.28\n",
      "Episode 107 -> Mean score 76.97\n",
      "Episode 108 -> Mean score 78.83\n",
      "Episode 109 -> Mean score 79.62\n",
      "Episode 110 -> Mean score 81.5\n",
      "Episode 111 -> Mean score 83.38\n",
      "Episode 112 -> Mean score 83.91\n",
      "Episode 113 -> Mean score 85.42\n",
      "Episode 114 -> Mean score 85.93\n",
      "Episode 115 -> Mean score 87.69\n",
      "Episode 116 -> Mean score 89.43\n",
      "Episode 117 -> Mean score 91.16\n",
      "Episode 118 -> Mean score 91.54\n",
      "Episode 119 -> Mean score 92.03\n",
      "* Saved training info\n",
      "INFO:tensorflow:Assets written to: saved_data/model_/assets\n",
      "* Saved model\n",
      "* Saved memory buffer\n",
      "Episode 120 -> Mean score 93.67\n",
      "Episode 121 -> Mean score 95.45\n",
      "Episode 122 -> Mean score 95.71\n",
      "Episode 123 -> Mean score 96.12\n",
      "Episode 124 -> Mean score 96.4\n",
      "Episode 125 -> Mean score 96.58\n",
      "Episode 126 -> Mean score 98.43\n",
      "Episode 127 -> Mean score 100.26\n",
      "Episode 128 -> Mean score 102.11\n",
      "Episode 129 -> Mean score 103.98\n",
      "Episode 130 -> Mean score 105.85\n",
      "Episode 131 -> Mean score 107.66\n",
      "Episode 132 -> Mean score 109.52\n",
      "Episode 133 -> Mean score 111.4\n",
      "Episode 134 -> Mean score 113.29\n",
      "Episode 135 -> Mean score 113.58\n",
      "Episode 136 -> Mean score 115.49\n",
      "Episode 137 -> Mean score 117.4\n",
      "Episode 138 -> Mean score 118.6\n",
      "Episode 139 -> Mean score 120.51\n",
      "* Saved training info\n",
      "INFO:tensorflow:Assets written to: saved_data/model_/assets\n",
      "* Saved model\n",
      "* Saved memory buffer\n",
      "Episode 140 -> Mean score 122.43\n",
      "Episode 141 -> Mean score 124.34\n",
      "Episode 142 -> Mean score 126.25\n",
      "Episode 143 -> Mean score 128.16\n",
      "Episode 144 -> Mean score 130.07\n",
      "Episode 145 -> Mean score 131.97\n",
      "Episode 146 -> Mean score 133.87\n",
      "Episode 147 -> Mean score 135.79\n",
      "Episode 148 -> Mean score 137.71\n",
      "Episode 149 -> Mean score 139.61\n",
      "Episode 150 -> Mean score 141.52\n",
      "Episode 151 -> Mean score 143.43\n",
      "Episode 152 -> Mean score 145.32\n",
      "Episode 153 -> Mean score 147.13\n",
      "Episode 154 -> Mean score 148.87\n",
      "Episode 155 -> Mean score 150.49\n",
      "Episode 156 -> Mean score 152.11\n",
      "Episode 157 -> Mean score 153.72\n",
      "Episode 158 -> Mean score 155.31\n",
      "Episode 159 -> Mean score 156.83\n",
      "* Saved training info\n",
      "INFO:tensorflow:Assets written to: saved_data/model_/assets\n",
      "* Saved model\n",
      "* Saved memory buffer\n",
      "Episode 160 -> Mean score 158.07\n",
      "Episode 161 -> Mean score 158.92\n",
      "Episode 162 -> Mean score 160.46\n",
      "Episode 163 -> Mean score 160.92\n",
      "Episode 164 -> Mean score 162.43\n",
      "Episode 165 -> Mean score 163.78\n",
      "Episode 166 -> Mean score 165.31\n",
      "Episode 167 -> Mean score 166.25\n",
      "Episode 168 -> Mean score 167.69\n",
      "Episode 169 -> Mean score 167.69\n",
      "Episode 170 -> Mean score 168.89\n",
      "Episode 171 -> Mean score 170.5\n",
      "Episode 172 -> Mean score 170.5\n",
      "Episode 173 -> Mean score 171.34\n",
      "Episode 174 -> Mean score 171.34\n",
      "Episode 175 -> Mean score 172.81\n",
      "Episode 176 -> Mean score 173.11\n",
      "Episode 177 -> Mean score 173.11\n",
      "Episode 178 -> Mean score 173.11\n",
      "Episode 179 -> Mean score 173.11\n",
      "* Saved training info\n",
      "INFO:tensorflow:Assets written to: saved_data/model_/assets\n",
      "* Saved model\n",
      "* Saved memory buffer\n",
      "Episode 180 -> Mean score 174.97\n",
      "Episode 181 -> Mean score 174.46\n",
      "Episode 182 -> Mean score 174.05\n",
      "Episode 183 -> Mean score 175.47\n",
      "Episode 184 -> Mean score 176.32\n",
      "Episode 185 -> Mean score 176.32\n",
      "Episode 186 -> Mean score 176.34\n",
      "Episode 187 -> Mean score 177.45\n",
      "Episode 188 -> Mean score 178.66\n",
      "Episode 189 -> Mean score 178.66\n",
      "Episode 190 -> Mean score 178.66\n",
      "Episode 191 -> Mean score 178.66\n",
      "Episode 192 -> Mean score 178.66\n",
      "Episode 193 -> Mean score 178.66\n",
      "Episode 194 -> Mean score 178.66\n",
      "Episode 195 -> Mean score 178.66\n",
      "Episode 196 -> Mean score 178.66\n",
      "Episode 197 -> Mean score 178.66\n",
      "Episode 198 -> Mean score 178.75\n",
      "Episode 199 -> Mean score 178.75\n",
      "* Saved training info\n",
      "INFO:tensorflow:Assets written to: saved_data/model_/assets\n",
      "* Saved model\n",
      "* Saved memory buffer\n",
      "Episode 200 -> Mean score 179.52\n",
      "Episode 201 -> Mean score 179.52\n",
      "Episode 202 -> Mean score 179.52\n",
      "Episode 203 -> Mean score 179.52\n",
      "Episode 204 -> Mean score 180.14\n",
      "Episode 205 -> Mean score 180.45\n",
      "Episode 206 -> Mean score 180.45\n",
      "Episode 207 -> Mean score 181.67\n",
      "Episode 208 -> Mean score 181.67\n",
      "Episode 209 -> Mean score 182.77\n",
      "Episode 210 -> Mean score 182.77\n",
      "Episode 211 -> Mean score 182.77\n",
      "Episode 212 -> Mean score 184.09\n",
      "Episode 213 -> Mean score 184.09\n",
      "Episode 214 -> Mean score 185.48\n",
      "Episode 215 -> Mean score 185.48\n",
      "Episode 216 -> Mean score 185.48\n",
      "Episode 217 -> Mean score 185.48\n",
      "Episode 218 -> Mean score 186.76\n",
      "Episode 219 -> Mean score 187.99\n",
      "* Saved training info\n",
      "INFO:tensorflow:Assets written to: saved_data/model_/assets\n",
      "* Saved model\n",
      "* Saved memory buffer\n",
      "Episode 220 -> Mean score 187.99\n",
      "Episode 221 -> Mean score 187.99\n",
      "Episode 222 -> Mean score 189.52\n",
      "Episode 223 -> Mean score 190.88\n",
      "Episode 224 -> Mean score 192.35\n",
      "Episode 225 -> Mean score 193.91\n",
      "Episode 226 -> Mean score 193.91\n",
      "Episode 227 -> Mean score 193.91\n",
      "Episode 228 -> Mean score 193.91\n",
      "Episode 229 -> Mean score 193.91\n",
      "Episode 230 -> Mean score 193.91\n",
      "Episode 231 -> Mean score 193.91\n",
      "Episode 232 -> Mean score 193.91\n",
      "Episode 233 -> Mean score 193.91\n",
      "Episode 234 -> Mean score 193.91\n",
      "Episode 235 -> Mean score 195.52\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0b1e8c3dad10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQNAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-de0207fa78cf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_episodes)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Episode {} -> Mean score {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_ep_trained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mmean_score\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m195\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Solved!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Final epsilon value is {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scores' is not defined"
     ]
    }
   ],
   "source": [
    "agent = DQNAgent()\n",
    "agent.train(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Model exists, loaded\n",
      "* Loaded info:\n",
      "Model already trained on 220 episodes\n",
      "Average score on previous 100 episodes is 187.99\n",
      "* Loaded memory buffer:\n",
      "Has 1000 tuples\n",
      "Already trained on 220 episodes\n",
      "Training on remaining 280\n",
      "** Training \n",
      "Episode 220 -> Mean score 187.99\n",
      "Episode 221 -> Mean score 187.99\n",
      "Episode 222 -> Mean score 189.52\n",
      "Episode 223 -> Mean score 190.88\n",
      "Episode 224 -> Mean score 192.35\n",
      "Episode 225 -> Mean score 193.91\n",
      "Episode 226 -> Mean score 193.91\n",
      "Episode 227 -> Mean score 193.91\n",
      "Episode 228 -> Mean score 193.91\n",
      "Episode 229 -> Mean score 193.91\n",
      "Episode 230 -> Mean score 193.91\n",
      "Episode 231 -> Mean score 193.45\n",
      "Episode 232 -> Mean score 193.45\n",
      "Episode 233 -> Mean score 193.45\n",
      "Episode 234 -> Mean score 193.45\n",
      "Episode 235 -> Mean score 195.06\n",
      "Solved!\n",
      "Final epsilon value is 0.01\n",
      "* Saved training info\n",
      "INFO:tensorflow:Assets written to: saved_data/model_/assets\n",
      "* Saved model\n",
      "* Saved memory buffer\n"
     ]
    }
   ],
   "source": [
    "agent = DQNAgent()\n",
    "agent.train(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([x+1 for x in range(len(agent.mean_scores))], agent.mean_scores)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Average reward over 100 episodes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previous failed attempt\n",
    "Why is the score reducing\n",
    "- Model diverged? \n",
    "- Not exploring randomly enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Model exists, loaded\n",
      "* Loaded info:\n",
      "Model already trained on 0 episodes\n",
      "* Loaded memory buffer:\n",
      "Has 0 tuples\n",
      "** Training \n",
      "Episode 1 -> Mean score 30.0\n",
      "Episode 2 -> Mean score 20.5\n",
      "Episode 3 -> Mean score 26.666666666666668\n",
      "Episode 4 -> Mean score 23.0\n",
      "Episode 5 -> Mean score 22.0\n",
      "Episode 6 -> Mean score 22.666666666666668\n",
      "Episode 7 -> Mean score 25.142857142857142\n",
      "Episode 8 -> Mean score 25.625\n",
      "Episode 9 -> Mean score 25.0\n",
      "Episode 10 -> Mean score 24.8\n",
      "Episode 11 -> Mean score 23.454545454545453\n",
      "Episode 12 -> Mean score 24.583333333333332\n",
      "Episode 13 -> Mean score 26.153846153846153\n",
      "Episode 14 -> Mean score 26.857142857142858\n",
      "Episode 15 -> Mean score 29.666666666666668\n",
      "Episode 16 -> Mean score 29.0625\n",
      "Episode 17 -> Mean score 28.705882352941178\n",
      "Episode 18 -> Mean score 28.055555555555557\n",
      "Episode 19 -> Mean score 30.57894736842105\n",
      "Episode 20 -> Mean score 37.8\n",
      "Episode 21 -> Mean score 37.095238095238095\n",
      "Episode 22 -> Mean score 36.72727272727273\n",
      "Episode 23 -> Mean score 37.43478260869565\n",
      "Episode 24 -> Mean score 41.333333333333336\n",
      "Episode 25 -> Mean score 47.68\n",
      "Episode 26 -> Mean score 48.23076923076923\n",
      "Episode 27 -> Mean score 53.851851851851855\n",
      "Episode 28 -> Mean score 52.5\n",
      "Episode 29 -> Mean score 55.48275862068966\n",
      "Episode 30 -> Mean score 60.3\n",
      "Episode 31 -> Mean score 59.32258064516129\n",
      "Episode 32 -> Mean score 63.71875\n",
      "Episode 33 -> Mean score 63.27272727272727\n",
      "Episode 34 -> Mean score 61.73529411764706\n",
      "Episode 35 -> Mean score 60.542857142857144\n",
      "Episode 36 -> Mean score 64.41666666666667\n",
      "Episode 37 -> Mean score 68.08108108108108\n",
      "Episode 38 -> Mean score 68.47368421052632\n",
      "Episode 39 -> Mean score 71.84615384615384\n",
      "Episode 40 -> Mean score 75.05\n",
      "Episode 41 -> Mean score 75.07317073170732\n",
      "Episode 42 -> Mean score 78.04761904761905\n",
      "Episode 43 -> Mean score 76.65116279069767\n",
      "Episode 44 -> Mean score 75.1590909090909\n",
      "Episode 45 -> Mean score 74.77777777777777\n",
      "Episode 46 -> Mean score 75.6086956521739\n",
      "Episode 47 -> Mean score 77.95744680851064\n",
      "Episode 48 -> Mean score 76.5625\n",
      "Episode 49 -> Mean score 79.08163265306122\n",
      "Episode 50 -> Mean score 81.5\n",
      "Episode 51 -> Mean score 83.82352941176471\n",
      "Episode 52 -> Mean score 86.0576923076923\n",
      "Episode 53 -> Mean score 88.20754716981132\n",
      "Episode 54 -> Mean score 90.27777777777777\n",
      "Episode 55 -> Mean score 92.27272727272727\n",
      "Episode 56 -> Mean score 91.46428571428571\n",
      "Episode 57 -> Mean score 92.29824561403508\n",
      "Episode 58 -> Mean score 94.15517241379311\n",
      "Episode 59 -> Mean score 93.76271186440678\n",
      "Episode 60 -> Mean score 94.21666666666667\n",
      "Episode 61 -> Mean score 95.95081967213115\n",
      "Episode 62 -> Mean score 97.12903225806451\n",
      "Episode 63 -> Mean score 97.34920634920636\n",
      "Episode 64 -> Mean score 96.109375\n",
      "Episode 65 -> Mean score 95.07692307692308\n",
      "Episode 66 -> Mean score 94.51515151515152\n",
      "Episode 67 -> Mean score 94.17910447761194\n",
      "Episode 68 -> Mean score 93.1029411764706\n",
      "Episode 69 -> Mean score 92.21739130434783\n",
      "Episode 70 -> Mean score 91.14285714285714\n",
      "Episode 71 -> Mean score 90.1830985915493\n",
      "Episode 72 -> Mean score 90.02777777777777\n",
      "Episode 73 -> Mean score 88.95890410958904\n",
      "Episode 74 -> Mean score 87.93243243243244\n",
      "Episode 75 -> Mean score 89.42666666666666\n",
      "Episode 76 -> Mean score 89.46052631578948\n",
      "Episode 77 -> Mean score 90.8961038961039\n",
      "Episode 78 -> Mean score 92.2948717948718\n",
      "Episode 79 -> Mean score 91.32911392405063\n",
      "Episode 80 -> Mean score 91.625\n",
      "Episode 81 -> Mean score 91.17283950617283\n",
      "Episode 82 -> Mean score 90.39024390243902\n",
      "Episode 83 -> Mean score 89.91566265060241\n",
      "Episode 84 -> Mean score 89.08333333333333\n",
      "Episode 85 -> Mean score 88.18823529411765\n",
      "Episode 86 -> Mean score 87.55813953488372\n",
      "Episode 87 -> Mean score 88.24137931034483\n",
      "Episode 88 -> Mean score 87.47727272727273\n",
      "Episode 89 -> Mean score 86.64044943820225\n",
      "Episode 90 -> Mean score 85.91111111111111\n",
      "Episode 91 -> Mean score 85.36263736263736\n",
      "Episode 92 -> Mean score 84.69565217391305\n",
      "Episode 93 -> Mean score 84.51612903225806\n",
      "Episode 94 -> Mean score 83.73404255319149\n",
      "Episode 95 -> Mean score 82.97894736842105\n",
      "Episode 96 -> Mean score 82.22916666666667\n",
      "Episode 97 -> Mean score 81.49484536082474\n",
      "Episode 98 -> Mean score 80.77551020408163\n",
      "Episode 99 -> Mean score 80.06060606060606\n",
      "Episode 100 -> Mean score 79.37\n",
      "Episode 101 -> Mean score 79.2\n",
      "Episode 102 -> Mean score 79.19\n",
      "Episode 103 -> Mean score 78.93\n",
      "Episode 104 -> Mean score 79.01\n",
      "Episode 105 -> Mean score 79.07\n",
      "Episode 106 -> Mean score 78.98\n",
      "Episode 107 -> Mean score 78.71\n",
      "Episode 108 -> Mean score 78.62\n",
      "Episode 109 -> Mean score 78.55\n",
      "Episode 110 -> Mean score 78.44\n",
      "Episode 111 -> Mean score 78.47\n",
      "Episode 112 -> Mean score 78.34\n",
      "Episode 113 -> Mean score 77.98\n",
      "Episode 114 -> Mean score 77.72\n",
      "Episode 115 -> Mean score 77.13\n",
      "Episode 116 -> Mean score 77.04\n",
      "Episode 117 -> Mean score 76.92\n",
      "Episode 118 -> Mean score 77.16\n",
      "Episode 119 -> Mean score 76.51\n",
      "Episode 120 -> Mean score 74.87\n",
      "Episode 121 -> Mean score 74.77\n",
      "Episode 122 -> Mean score 74.68\n",
      "Episode 123 -> Mean score 74.76\n",
      "Episode 124 -> Mean score 73.57\n",
      "Episode 125 -> Mean score 71.69\n",
      "Episode 126 -> Mean score 71.34\n",
      "Episode 127 -> Mean score 69.45\n",
      "Episode 128 -> Mean score 69.4\n",
      "Episode 129 -> Mean score 68.16\n",
      "Episode 130 -> Mean score 66.29\n",
      "Episode 131 -> Mean score 66.25\n",
      "Episode 132 -> Mean score 64.35\n",
      "Episode 133 -> Mean score 63.97\n",
      "Episode 134 -> Mean score 63.98\n",
      "Episode 135 -> Mean score 63.91\n",
      "Episode 136 -> Mean score 62.02\n",
      "Episode 137 -> Mean score 60.13\n",
      "Episode 138 -> Mean score 59.41\n",
      "Episode 139 -> Mean score 57.56\n",
      "Episode 140 -> Mean score 55.67\n",
      "Episode 141 -> Mean score 55.01\n",
      "Episode 142 -> Mean score 53.13\n",
      "Episode 143 -> Mean score 53.08\n",
      "Episode 144 -> Mean score 53.1\n",
      "Episode 145 -> Mean score 52.66\n",
      "Episode 146 -> Mean score 51.62\n",
      "Episode 147 -> Mean score 49.86\n",
      "Episode 148 -> Mean score 49.84\n",
      "Episode 149 -> Mean score 48.01\n",
      "Episode 150 -> Mean score 46.1\n",
      "Episode 151 -> Mean score 44.21\n",
      "Episode 152 -> Mean score 42.32\n",
      "Episode 153 -> Mean score 40.42\n",
      "Episode 154 -> Mean score 38.56\n",
      "Episode 155 -> Mean score 36.66\n",
      "Episode 156 -> Mean score 36.28\n",
      "Episode 157 -> Mean score 35.04\n",
      "Episode 158 -> Mean score 33.13\n",
      "Episode 159 -> Mean score 32.52\n",
      "Episode 160 -> Mean score 31.42\n",
      "Episode 161 -> Mean score 29.51\n",
      "Episode 162 -> Mean score 27.92\n",
      "Episode 163 -> Mean score 26.92\n",
      "Episode 164 -> Mean score 26.84\n",
      "Episode 165 -> Mean score 26.65\n",
      "Episode 166 -> Mean score 26.17\n",
      "Episode 167 -> Mean score 25.55\n",
      "Episode 168 -> Mean score 25.44\n",
      "Episode 169 -> Mean score 25.23\n",
      "Episode 170 -> Mean score 25.15\n",
      "Episode 171 -> Mean score 25.03\n",
      "Episode 172 -> Mean score 24.35\n",
      "Episode 173 -> Mean score 24.33\n",
      "Episode 174 -> Mean score 24.3\n",
      "Episode 175 -> Mean score 22.48\n",
      "Episode 176 -> Mean score 21.66\n",
      "Episode 177 -> Mean score 19.77\n",
      "Episode 178 -> Mean score 17.88\n",
      "Episode 179 -> Mean score 17.83\n",
      "Episode 180 -> Mean score 16.78\n",
      "Episode 181 -> Mean score 16.33\n",
      "Episode 182 -> Mean score 16.17\n",
      "Episode 183 -> Mean score 15.77\n",
      "Episode 184 -> Mean score 15.68\n",
      "Episode 185 -> Mean score 15.66\n",
      "Episode 186 -> Mean score 15.44\n",
      "Episode 187 -> Mean score 14.18\n",
      "Episode 188 -> Mean score 14.08\n",
      "Episode 189 -> Mean score 14.11\n",
      "Episode 190 -> Mean score 14.11\n",
      "Episode 191 -> Mean score 13.91\n",
      "Episode 192 -> Mean score 13.78\n",
      "Episode 193 -> Mean score 13.2\n",
      "Episode 194 -> Mean score 13.22\n",
      "Episode 195 -> Mean score 13.24\n",
      "Episode 196 -> Mean score 13.31\n",
      "Episode 197 -> Mean score 13.32\n",
      "Episode 198 -> Mean score 13.34\n",
      "Episode 199 -> Mean score 13.83\n",
      "Episode 200 -> Mean score 13.86\n",
      "Episode 201 -> Mean score 13.86\n",
      "Episode 202 -> Mean score 14.06\n",
      "Episode 203 -> Mean score 14.24\n",
      "Episode 204 -> Mean score 14.27\n",
      "Episode 205 -> Mean score 14.15\n",
      "Episode 206 -> Mean score 14.11\n",
      "Episode 207 -> Mean score 14.49\n",
      "Episode 208 -> Mean score 14.69\n",
      "Episode 209 -> Mean score 14.84\n",
      "Episode 210 -> Mean score 14.85\n",
      "Episode 211 -> Mean score 14.86\n",
      "Episode 212 -> Mean score 14.74\n",
      "Episode 213 -> Mean score 14.81\n",
      "Episode 214 -> Mean score 14.84\n",
      "Episode 215 -> Mean score 14.85\n",
      "Episode 216 -> Mean score 14.88\n",
      "Episode 217 -> Mean score 14.88\n",
      "Episode 218 -> Mean score 14.6\n",
      "Episode 219 -> Mean score 14.62\n",
      "Episode 220 -> Mean score 14.64\n",
      "Episode 221 -> Mean score 14.62\n",
      "Episode 222 -> Mean score 14.54\n",
      "Episode 223 -> Mean score 14.03\n",
      "Episode 224 -> Mean score 14.03\n",
      "Episode 225 -> Mean score 14.04\n",
      "Episode 226 -> Mean score 13.9\n",
      "Episode 227 -> Mean score 13.96\n",
      "Episode 228 -> Mean score 13.97\n",
      "Episode 229 -> Mean score 13.92\n",
      "Episode 230 -> Mean score 13.9\n",
      "Episode 231 -> Mean score 13.74\n",
      "Episode 232 -> Mean score 13.76\n",
      "Episode 233 -> Mean score 13.77\n",
      "Episode 234 -> Mean score 13.78\n",
      "Episode 235 -> Mean score 13.75\n",
      "Episode 236 -> Mean score 13.82\n",
      "Episode 237 -> Mean score 13.83\n",
      "Episode 238 -> Mean score 13.84\n",
      "Episode 239 -> Mean score 13.82\n",
      "Episode 240 -> Mean score 13.84\n",
      "Episode 241 -> Mean score 13.87\n",
      "Episode 242 -> Mean score 13.88\n",
      "Episode 243 -> Mean score 13.87\n",
      "Episode 244 -> Mean score 13.88\n",
      "Episode 245 -> Mean score 13.87\n",
      "Episode 246 -> Mean score 13.89\n",
      "Episode 247 -> Mean score 13.9\n",
      "Episode 248 -> Mean score 13.92\n",
      "Episode 249 -> Mean score 13.87\n",
      "Episode 250 -> Mean score 13.89\n",
      "Episode 251 -> Mean score 13.89\n",
      "Episode 252 -> Mean score 14.11\n",
      "Episode 253 -> Mean score 14.13\n",
      "Episode 254 -> Mean score 14.09\n",
      "Episode 255 -> Mean score 14.11\n",
      "Episode 256 -> Mean score 14.27\n",
      "Episode 257 -> Mean score 14.35\n",
      "Episode 258 -> Mean score 14.39\n",
      "Episode 259 -> Mean score 14.44\n",
      "Episode 260 -> Mean score 14.44\n",
      "Episode 261 -> Mean score 14.56\n",
      "Episode 262 -> Mean score 14.59\n",
      "Episode 263 -> Mean score 14.74\n",
      "Episode 264 -> Mean score 14.83\n",
      "Episode 265 -> Mean score 14.87\n",
      "Episode 266 -> Mean score 14.92\n",
      "Episode 267 -> Mean score 14.96\n",
      "Episode 268 -> Mean score 15.05\n",
      "Episode 269 -> Mean score 15.12\n",
      "Episode 270 -> Mean score 15.18\n",
      "Episode 271 -> Mean score 15.21\n",
      "Episode 272 -> Mean score 15.25\n",
      "Episode 273 -> Mean score 15.33\n",
      "Episode 274 -> Mean score 15.42\n",
      "Episode 275 -> Mean score 15.63\n",
      "Episode 276 -> Mean score 15.73\n",
      "Episode 277 -> Mean score 15.81\n",
      "Episode 278 -> Mean score 15.87\n",
      "Episode 279 -> Mean score 16.08\n",
      "Episode 280 -> Mean score 16.18\n",
      "Episode 281 -> Mean score 16.28\n",
      "Episode 282 -> Mean score 16.37\n",
      "Episode 283 -> Mean score 16.44\n",
      "Episode 284 -> Mean score 16.61\n",
      "Episode 285 -> Mean score 16.67\n",
      "Episode 286 -> Mean score 16.87\n",
      "Episode 287 -> Mean score 16.89\n",
      "Episode 288 -> Mean score 17.06\n",
      "Episode 289 -> Mean score 17.12\n",
      "Episode 290 -> Mean score 17.32\n",
      "Episode 291 -> Mean score 17.38\n",
      "Episode 292 -> Mean score 17.61\n",
      "Episode 293 -> Mean score 17.76\n",
      "Episode 294 -> Mean score 17.88\n",
      "Episode 295 -> Mean score 17.97\n",
      "Episode 296 -> Mean score 18.14\n",
      "Episode 297 -> Mean score 18.49\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-359e45e880a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQNAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-8917d64a7060>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_episodes)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m                 \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-8917d64a7060>\u001b[0m in \u001b[0;36mfit_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0my_desired\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0my_desired\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m           \u001b[0mcount_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'samples'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_sample\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'steps'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Handle ProgBarLogger separately in this loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m           mode=mode)\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m       with training_context.on_start(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mconfigure_callbacks\u001b[0;34m(callbacks, model, do_validation, batch_size, epochs, steps_per_epoch, samples, verbose, count_mode, mode)\u001b[0m\n\u001b[1;32m    116\u001b[0m       \u001b[0msamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m       \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m       mode=mode)\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m   \u001b[0mcallback_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mset_callback_parameters\u001b[0;34m(callback_list, model, do_validation, batch_size, epochs, steps_per_epoch, samples, verbose, mode)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mWhich\u001b[0m \u001b[0mloop\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mto\u001b[0m \u001b[0mconfigure\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m   \"\"\"\n\u001b[0;32m--> 147\u001b[0;31m   \u001b[0mmetric_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallback_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseLogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProgbarLogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mmetrics_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0;31m# Add all metric names.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m     \u001b[0mmetrics_names\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mmetrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    483\u001b[0m       \u001b[0mmetrics\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_metric_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m     \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_metrics_from_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_get_metrics_from_layers\u001b[0;34m(layers)\u001b[0m\n\u001b[1;32m   3224\u001b[0m   \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3225\u001b[0m   \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrackable_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_empty_layer_containers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3226\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3227\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3228\u001b[0m       \u001b[0;31m# We cannot call 'metrics' on the model because we do not want to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/layer_utils.py\u001b[0m in \u001b[0;36mfilter_empty_layer_containers\u001b[0;34m(layer_list)\u001b[0m\n\u001b[1;32m    242\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0mexisting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m       \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/layer_utils.py\u001b[0m in \u001b[0;36mis_layer\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;34m\"\"\"Implicit check for Layer-like objects.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0;31m# TODO(b/110718070): Replace with isinstance(obj, base_layer.Layer).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_is_layer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent = DQNAgent()\n",
    "agent.train(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "Deep Q Learning with Experience Replay  \n",
    "\n",
    "https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf\n",
    "\n",
    "\n",
    "Parameter values from \n",
    "\n",
    "https://gist.github.com/mbalunovic/fb7392e2c09b2c3895a354c3ad36497e#file-cartpole_q_network-py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
